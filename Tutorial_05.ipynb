{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lalopezpa/stochastics/blob/main/Tutorial_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-SLarXEvXDA"
      },
      "source": [
        "\n",
        "\n",
        "![tud_logo_og_square.png](data:image/png;base64,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)\n",
        "\n",
        ">**Stochastic Modeling and Simulation**\n",
        "\n",
        "> Winter Semester 2024/25\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuM5_iJ6wPrW"
      },
      "source": [
        "The following questions are for helping you in understanding the contents of the lecture. Your answers will not be collected or graded but we will discuss the solutions in the class. If you cannot easily answer the questions or have doubts regarding the correctness of your answers, please take a few minutes to review the contents in the book or through the web. Also, please feel free to ask your questions and concerns about the questions in the tutorial classes or in the Forum in the Opal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAEzOBXgrKOv"
      },
      "source": [
        "In the code cells, please change the ***None*** values between **##start** and **##end** to a desirable code or value. Then, you can run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-uTqJogE34_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "from scipy.integrate import quad\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEfxE65SDu6g"
      },
      "source": [
        "# The Law of Large Numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oQO0DxaDu6h"
      },
      "source": [
        "We saw two forms of the law of large numbers:\n",
        "\n",
        "1.   The weak law which state that\n",
        "\n",
        " $P(|\\dfrac{x_{1}+x_{2}+ ... +x_{n}}{n}-\\mu| \\ge \\epsilon ) \\rightarrow 0 $  \n",
        "\n",
        " for any $\\epsilon \\ge 0$ as  $n \\rightarrow \\infty$\n",
        "2.   The strong law which state that\n",
        "\n",
        " $\\dfrac{x_{1}+x_{2}+ ... +x_{n}}{n} \\rightarrow \\mu $  \n",
        "\n",
        " as  $n \\rightarrow \\infty$\n",
        "\n",
        "\n",
        "Do you remember the dice experiment in exercise two, in which we wanted to estimate the $Exp(x)$ where $x$ was the sum of ten different dice? What if we get the average of the outcome dices as our RV?\n",
        "\n",
        "In the code box below, you can simulate this experiment with different dice numbers. The codes are almost the same as exercise 2, with only two differences:\n",
        "\n",
        "\n",
        "1.\n",
        "$x = \\dfrac{dice_1+dice_2+...+dice_3}{numbers\\space of\\space dice} $\n",
        "\n",
        "2. We repeat the experiment for different numbers of dice.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qe3i6OCADu6i"
      },
      "outputs": [],
      "source": [
        "def Experiment(numbers_of_dice, n_trials):\n",
        "    # Set the number of trials\n",
        "    N = n_trials\n",
        "\n",
        "    # Initialize an array to store the sum of dice rolls for each trial\n",
        "    sum = np.zeros(N)\n",
        "\n",
        "    # Loop through each dice roll\n",
        "    for i in tqdm(range(numbers_of_dice)):\n",
        "        sum += np.random.randint(low=1, high=7, size=N, dtype=int)\n",
        "\n",
        "    # Compute the average of the dice rolls across all trials\n",
        "    x = sum / numbers_of_dice\n",
        "\n",
        "    return x\n",
        "\n",
        "# Set the number of trials for the experiment\n",
        "n_trials = 10000\n",
        "\n",
        "# Define a list of different numbers of dice to experiment with\n",
        "numbers_list = [10, 100]\n",
        "\n",
        "# Visualizing the outcomes\n",
        "fig1, axes = plt.subplots(1, 2)\n",
        "\n",
        "# Loop through each number of dice\n",
        "for i, n in enumerate(numbers_list):\n",
        "    ax = axes[i]\n",
        "    x = Experiment(n, n_trials)\n",
        "    unique, counts = np.unique(x, return_counts=True)\n",
        "    ax.scatter(unique, counts)\n",
        "    ax.set_xlabel(\"possible outcome\")\n",
        "\n",
        "    if i == 0:\n",
        "        ax.set_ylabel(\"frequency\")\n",
        "\n",
        "    ax.set_title(f\"number of different \\n dices = {n}\")\n",
        "    plt.subplots_adjust(wspace=0.4)\n",
        "    ax.set_xlim([0, 7])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "plt.show()\n",
        "plt.close(fig1)\n",
        "\n",
        "# Repeat the process for a different set of numbers of dice\n",
        "n_trials = 10000\n",
        "numbers_list = [1000, 10000]\n",
        "fig2, axes = plt.subplots(1, 2)\n",
        "\n",
        "for i, n in enumerate(numbers_list):\n",
        "    ax = axes[i]\n",
        "    x = Experiment(n, n_trials)\n",
        "    unique, counts = np.unique(x, return_counts=True)\n",
        "    ax.scatter(unique, counts)\n",
        "    ax.set_xlabel(\"possible outcome\")\n",
        "\n",
        "    if i == 0:\n",
        "        ax.set_ylabel(\"frequency\")\n",
        "\n",
        "    ax.set_title(f\"number of different \\n dices = {n}\")\n",
        "    plt.subplots_adjust(wspace=0.4)\n",
        "    ax.set_xlim([0, 7])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "plt.show()\n",
        "plt.close(fig2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F_3C2hwDu6i"
      },
      "source": [
        "These plots illustrate how the mean converges to $\\mu = 3.5$ as the total number of dice increases, showing the law of large numbers in action.\n",
        "\n",
        "We can also prove this law mathematically in different ways. One way could be using \"Chebyshev's inequality\".\n",
        "\n",
        "Chebyshev's inequality states that for every random variable $X$:\n",
        "\n",
        "$P(|X-E(X)|\\ge a) \\space \\le \\space \\dfrac{Var(X)}{a^2}$\n",
        "\n",
        "and $a$ can be **any number more than zero**.\n",
        "\n",
        "As an exercise, prove the Weak Law of Large Numbers using Chebyshev's inequality.  \\\\\n",
        "\n",
        "\n",
        "\n",
        "(**Hint**: Consider your RV as $\\space Y =  \\dfrac{x_{1}+x_{2}+ ... +x_{n}}{n}$\n",
        "\n",
        "and show that $\\lim_{n \\rightarrow \\infty} P(| Y - \\mu | \\geq \\varepsilon) = \\lim_{N \\rightarrow \\infty} P(| \\overline{X}_N - \\mu | \\geq \\varepsilon) = 0$)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC3f_EdoDu6j"
      },
      "source": [
        "The other way to prove this law is by using the Characteristic function of the random variables. The characteristic function is an alternative way to describe a random variable and is defined as $\\varphi _x (t) := \\mathbb{E}[e^{itx}]$ for a random variable $X$. In other words, if a random variable admits a probability density function, the characteristic function is the **\"Fourier Transform\"** of the probability density function. Another exercise in this section is to prove the Weak Law of Large Numbers by demonstrating that the characteristic function of $ \\overline{X}_N = \\frac{1}{N} \\sum_{i=1}^N X_i $ converges to $ e^{it\\mu} $ as $ N \\to \\infty $.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIOQ0AQ6Rv24"
      },
      "source": [
        "# Monte Carlo Methods for Integration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTHvgPN1tUIU"
      },
      "source": [
        "consider function $H$ as below:\n",
        "\n",
        "\n",
        "\n",
        "$H_{(x,y)} =\n",
        "     \\begin{cases}\n",
        "       1 &\\quad\\text{if} \\space \\space x^2+y^2 \\le 1 \\\\\n",
        "       0 &\\quad\\text{otherwise}\n",
        "     \\end{cases}\n",
        "$\n",
        "\n",
        "\n",
        "\n",
        "Can you calculate the integral of this function as follows?\n",
        "\n",
        "$\\int_{- \\infty}^{\\infty}\\int_{- \\infty}^{\\infty} H_{(x,y)}\\;\\mathrm{d}x\\mathrm{d}y$\n",
        "\n",
        "Hint: use the shape of the function to calculate the integral"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGLrN0Djuew6"
      },
      "source": [
        "The bellow code can solve this integral using stochastic! This fantastic method, called \"Monte Carlo integration\", has been introduced in the lecture.\n",
        "\n",
        "Increase the number of samples in the code from 10 to 1000000 to see how the answer will converge to the analytical solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGhuj55jRwdg"
      },
      "outputs": [],
      "source": [
        "# Define the number of random samples\n",
        "N_Samples = 1000000\n",
        "\n",
        "# Set the radius of the circle (which fits inside a square)\n",
        "radius = 1\n",
        "\n",
        "# Generate random X and Y coordinates within the square [-1, 1] for both axes\n",
        "X = np.random.uniform(-radius, radius, N_Samples)\n",
        "Y = np.random.uniform(-radius, radius, N_Samples)\n",
        "\n",
        "# Initialize a counter for the number of points that lie inside the circle\n",
        "inside_circle = 0\n",
        "\n",
        "# Loop through each sample and check if it lies inside the circle\n",
        "for i in range(N_Samples):\n",
        "    if X[i]**2 + Y[i]**2 < radius**2:\n",
        "        inside_circle += 1\n",
        "\n",
        "# Estimate the area of the circle\n",
        "area = (inside_circle / N_Samples) * ((2 * radius) * 2)\n",
        "\n",
        "# The analytical solution for the area of a circle is pi (π)\n",
        "analytical_solution = np.pi\n",
        "\n",
        "# Print the analytical value of pi, the estimated area, and the error between the two\n",
        "print(\"Analytical Solution = pi\")\n",
        "print(\"Estimation = \", area)\n",
        "print(\"Error = \", abs(analytical_solution - area))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEzsDzxN8tkw"
      },
      "source": [
        "In the code cell below, we want to calculate the integral $\\int_{0}^{1} e^x\\;\\mathrm{d}x$ using the same method we estimated π in the above code:\n",
        "- First sample large number of uniform random variable from a Rectangle with $Width = (1 - 0)$ and $Length = (e^1 - 0)$.\n",
        "- Then see how many of these random numbers are under the curve.\n",
        "- Finally, we can estimate the area under the curve by this formula:\n",
        "\n",
        "  $Area\\space under\\space the\\space curve \\approx  \\dfrac{number\\space of\\space samples\\space under\\space the\\space curve}{Total\\space number\\space of\\space samples}\\cdot Area \\space of \\space the \\space rectangle$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbl5qDlW3iHs"
      },
      "outputs": [],
      "source": [
        "# Set the number of random samples\n",
        "N_Samples = 100\n",
        "\n",
        "# Define the bounds for the X and Y coordinates\n",
        "x_lower_bound = 0  # Lower bound for X (from 0 to 1)\n",
        "x_upper_bound = 1  # Upper bound for X (1)\n",
        "y_lower_bound = 0  # Lower bound for Y (0)\n",
        "##start\n",
        "y_upper_bound = None  # Upper bound for Y (?)\n",
        "##end\n",
        "\n",
        "# Generate random samples for X and Y using a uniform distribution within the bounds\n",
        "X = np.random.uniform(x_lower_bound, x_upper_bound, N_Samples)\n",
        "Y = np.random.uniform(y_lower_bound, y_upper_bound, N_Samples)\n",
        "\n",
        "# Lists to store points that are below the function (accepted) and above it (not accepted)\n",
        "x = []  # x-coordinates of accepted points\n",
        "y = []  # y-coordinates of accepted points\n",
        "x_e = []  # x-coordinates of not accepted points\n",
        "y_e = []  # y-coordinates of not accepted points\n",
        "\n",
        "# Counter for the number of points below the function (y = exp(x))\n",
        "bellow_function = 0\n",
        "\n",
        "# Loop through each random sample\n",
        "for i in range(N_Samples):\n",
        "\n",
        "    if np.exp(X[i]) > Y[i]:\n",
        "        bellow_function += 1\n",
        "        x.append(X[i])  # Store accepted x-coordinate\n",
        "        y.append(Y[i])  # Store accepted y-coordinate\n",
        "    else:\n",
        "        x_e.append(X[i])  # Store not accepted x-coordinate\n",
        "        y_e.append(Y[i])  # Store not accepted y-coordinate\n",
        "\n",
        "# Define the range for the x-axis for plotting\n",
        "x_axis = np.arange(0, 1, 0.01)\n",
        "\n",
        "# Plot the accepted points (below the function), not accepted points, and the function y = exp(x)\n",
        "plt.scatter(x, y, label=\"Accepted\")\n",
        "plt.scatter(x_e, y_e, label=\"Not Accepted\")\n",
        "plt.plot(x_axis, np.exp(x_axis), label=\"y = exp(x)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Calculate the area of the rectangle that bounds the region we're sampling from\n",
        "plane_area = (np.exp(1) - 0) * (1 - 0)\n",
        "\n",
        "# Analytical solution to the integral of y = exp(x) from 0 to 1\n",
        "analytical_solution = np.exp(1) - np.exp(0)\n",
        "\n",
        "# Print the analytical solution (exact value of the integral)\n",
        "print(\"Analytical Solution =\", analytical_solution)\n",
        "\n",
        "# Estimate the integral using the proportion of accepted points to total points, multiplied by the area of the rectangle\n",
        "print(\"Estimation = \", (bellow_function / N_Samples) * plane_area)\n",
        "\n",
        "##start\n",
        "# Calculate the error by comparing the Monte Carlo estimate with the analytical solution\n",
        "print(\"Error = \", abs(analytical_solution - None))\n",
        "##end\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1XEps_hwkeO"
      },
      "source": [
        "The method used above can be referred to as Monte Carlo Integration with the Hit-or-Miss approach. Let's think about another approach.\n",
        "\n",
        "\n",
        "- Try evaluating the integral **$\\int_{0}^{1} e^x\\;\\mathrm{d}x$** again using Monte Carlo integration, but this time, rely on a single uniform random variable \\( X \\sim U(0,1) \\). Set the sample size to \\( N = 20 \\).  \n",
        "\n",
        "- Notice that, unlike the previous method where two random variables were used for \\( x \\) and \\( y \\), we now use only one. This approach is what is typically referred to as **Monte Carlo Integration**. In this method, defining an estimator is essential. What would the Monte Carlo estimator be in this example?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3111K5rH0YhD"
      },
      "outputs": [],
      "source": [
        "##start\n",
        "N_Samples = None\n",
        "X = np.random.uniform(None, None, N_Samples)\n",
        "Exp_Value = np.sum(np.exp(X))/None\n",
        "##end\n",
        "MC_Estimator = (1-0)*Exp_Value\n",
        "analytical_solution = np.exp(1)-np.exp(0)\n",
        "print(\"Analytical Solution =\", analytical_solution )\n",
        "print(\"Estimation = \", MC_Estimator)\n",
        "print(\"Error = \", abs(analytical_solution-(1-0)*Exp_Value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQgfNVfpZ8rk"
      },
      "source": [
        "Let's write a code to use the sampled numbers and estimate the variance of our Monte Carlo Estimator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0drAYUPLx9W"
      },
      "outputs": [],
      "source": [
        "##start\n",
        "Variance = Variance = np.var(np.exp(X)) / None\n",
        "##end\n",
        "print(\"Estimation of our estimator variance = \", Variance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaDfQLjUZE_D"
      },
      "source": [
        "We know that $X$ follows a continuous uniform distribution with the probability density function (PDF):\n",
        "\n",
        "\\begin{equation*}\n",
        "f_X(x) = \\begin{cases}\n",
        "\\frac{1}{b - a} & \\text{if } a \\le x \\le b \\\\\n",
        "0 & \\text{otherwise}\n",
        "\\end{cases}\n",
        "\\end{equation*}\n",
        "\n",
        "Additionally, the moment generating function (MGF) for a continuous random variable $X$ is defined as:\n",
        "\n",
        "\\begin{equation*}\n",
        "M_X(t) = \\mathbb{E}(e^{tX}) = \\int_{-\\infty}^\\infty e^{tx} f_X(x) \\, dx\n",
        "\\end{equation*}\n",
        "\n",
        "Now, suppose you have the moment generating function for the uniform distribution and want to use the values of $ M_X(1) $ and $ M_X(2) $ to calculate the variance of the Monte Carlo Estimator used in the previous example, before starting the sampling. Derive the formula for this variance ($Var(\\theta_N)$).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blyvfRC4dr2M"
      },
      "source": [
        "Run the code cell bellow to compare the estimated value in the previous code cell with the variance you derived using MGF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TL_6WmQbCIe"
      },
      "outputs": [],
      "source": [
        "def mgf_uniform(t, a, b):\n",
        "    \"\"\"\n",
        "    Calculate the Moment Generating Function (MGF) for a Uniform(a, b) distribution.\n",
        "\n",
        "    Parameters:\n",
        "    t (float): The value at which to evaluate the MGF.\n",
        "    a (float): The lower bound of the uniform distribution.\n",
        "    b (float): The upper bound of the uniform distribution.\n",
        "\n",
        "    Returns:\n",
        "    float: The value of the MGF at t.\n",
        "    \"\"\"\n",
        "    if t == 0:\n",
        "        # Handle t = 0 case to avoid division by zero\n",
        "        return 1\n",
        "    else:\n",
        "        return (np.exp(t * b) - np.exp(t * a)) / (t * (b - a))\n",
        "\n",
        "a = 0  # Lower bound of uniform distribution\n",
        "b = 1  # Upper bound of uniform distribution\n",
        "\n",
        "##start\n",
        "variance = (mgf_uniform(2, a, b) - mgf_uniform(1, a, b) ** None) / None\n",
        "##end\n",
        "\n",
        "print(\"Variance of Monte Carlo Estimator:\", variance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oxak9G8fJj94"
      },
      "source": [
        "Let's extend our understanding to double integrals :\n",
        "\n",
        "- Evaluate the double integral $\\int\\int_{\\Omega} (3y - 2x^2)\\mathrm{d} x\\mathrm\n",
        "{d} y \\space$ analytically where $-1 \\le x \\le 2 \\space $ and $1 \\le y \\le 3$.\n",
        "\n",
        "- Can you define a Monte Carlo estimator for solving this integral?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgaTj4PrewCV"
      },
      "source": [
        "In the cell below, we want to define a function to get a number as sample size and return 1000 estimated solution for this integral as well as the variance of these estimations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cY6S-lpBbB_a"
      },
      "outputs": [],
      "source": [
        "def MC_estimator(sample_size):\n",
        "\n",
        "  # Set the number of samples per trial\n",
        "  N_Samples = sample_size\n",
        "\n",
        "  # Set the number of trials for repeated estimations\n",
        "  n_trials = 1000\n",
        "\n",
        "  # Initialize an array to store results from each trial\n",
        "  array = np.zeros((n_trials, N_Samples))\n",
        "\n",
        "  ##start\n",
        "  # Define the bounds for the x and y variables (to be set later)\n",
        "  x_lower_bound = -1\n",
        "  x_upper_bound = None\n",
        "  y_lower_bound = None\n",
        "  y_upper_bound = None\n",
        "  ##end\n",
        "\n",
        "  # Calculate the volume of the integration region (area of rectangle)\n",
        "  volume = (y_upper_bound - y_lower_bound) * (x_upper_bound - x_lower_bound)\n",
        "\n",
        "  # Loop through each trial to perform Monte Carlo estimation\n",
        "  for i in range(n_trials):\n",
        "    # Generate random samples for X and Y within the specified bounds\n",
        "    X = np.random.uniform(x_lower_bound, x_upper_bound, N_Samples)\n",
        "    Y = np.random.uniform(y_lower_bound, y_upper_bound, N_Samples)\n",
        "\n",
        "    # Evaluate the function F = 3Y - 2X^2 at the sampled points\n",
        "    F = 3 * Y - 2 * (X ** 2)\n",
        "\n",
        "    # Store the results in the array\n",
        "    array[i] = F\n",
        "\n",
        "  ##start\n",
        "  # Compute the Monte Carlo estimator\n",
        "  MC_estimator = None * np.mean(array, axis=1)\n",
        "  ##end\n",
        "\n",
        "  # Calculate the variance of the Monte Carlo estimator across trials\n",
        "  variance = np.var(MC_estimator)\n",
        "\n",
        "\n",
        "  return MC_estimator, variance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IIlTn1NcB1t"
      },
      "outputs": [],
      "source": [
        "# Define a list of different sample sizes to test\n",
        "sample_size = [10, 50, 100, 500, 1000]\n",
        "\n",
        "# Initialize lists to store variance and mean values for each sample size\n",
        "var = []\n",
        "mu = []\n",
        "\n",
        "# Loop over each sample size and compute the Monte Carlo estimator, variance, and mean\n",
        "for n in sample_size:\n",
        "  _, variance = MC_estimator(n)\n",
        "  var.append(variance)\n",
        "\n",
        "# Plot the variance of the Monte Carlo estimator as a function of sample size\n",
        "plt.plot(sample_size, var, label=\"MC_estimator variance\")\n",
        "plt.xlabel(\"Sample size\")\n",
        "plt.ylabel(\"Variance\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdviUP3iRw2Z"
      },
      "source": [
        "# Importance Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NTrJerLHTC7"
      },
      "source": [
        "Consider the function $f(x)=10e^{-2|x-5|}$ where $x\\sim U(0,10)$. Our goal is to compute the expectation of this function using two methods: simple Monte Carlo integration and importance sampling.\n",
        "\n",
        "\n",
        "-  Part 1: Write the mathematical formulation for the expectation of $f(x)$. Can you detemine the analytical result for this integration?\n",
        "-  Part 2: Define an estimator for this expectation using simple Monte Carlo integration, with samples drawn from a uniform distribution $U(0,10)$.\n",
        "-  Part 3: Define another estimator for the expectation using importance sampling, where samples are drawn from a Gaussian distribution $N(5,1)$.\n",
        "-  Part 4: Which estimator do you expect to have less variance? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae0-5ab2QlvI"
      },
      "source": [
        "\n",
        "\n",
        "> The following code cells will guide you step by step through each part of the problem, providing helpful hints and insights along the way.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BrcS3BZMSgm"
      },
      "outputs": [],
      "source": [
        "# Part 1: Defining the integral and solving it\n",
        "\n",
        "\n",
        "# Define the function for which we aim to calculate the integral.\n",
        "def H(x):\n",
        "    ##start\n",
        "    h = np.exp(-2 * np.abs(None))\n",
        "    ##end\n",
        "    return h\n",
        "\n",
        "# Integrate H(x) over the interval [0, 10]\n",
        "result, error = quad(H, 0, 10)\n",
        "\n",
        "print(f\"Integral result: {result}\")\n",
        "print(f\"Estimated error: {error}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoLRQUHPcrbE"
      },
      "outputs": [],
      "source": [
        "# Part 2: Using simple Monte Carlo integration, with samples drawn from a uniform distribution  U(0,10) .\n",
        "# Part 3: Using simple Monte Carlo integration and importance sampling, where samples are drawn from a Gaussian distribution  N(5,1) .\n",
        "\n",
        "\n",
        "# Define the function for which we aim to calculate the integral.\n",
        "def H(x):\n",
        "    return np.exp(-2 * np.abs(x - 5))\n",
        "\n",
        "# Monte Carlo estimator using uniform sdisr. for sampling\n",
        "def monte_carlo_uniform(N):\n",
        "    x_uniform = np.random.uniform(0, 10, N)\n",
        "\n",
        "    ##start\n",
        "    estimator = None * np.sum(H(x_uniform)) / N\n",
        "    ##end\n",
        "\n",
        "    return estimator\n",
        "\n",
        "\n",
        "# Monte Carlo with Importance sampling estimator using Gaussian dist. for sampling\n",
        "def importance_sampling_gaussian(N):\n",
        "    x_gaussian = np.random.normal(5, 1, N)\n",
        "    pdf_gaussian = (1 / np.sqrt(2 * np.pi)) * np.exp(-0.5 * (x_gaussian - 5)**2)\n",
        "    weights = 1 / pdf_gaussian\n",
        "\n",
        "    ##start\n",
        "    estimator = np.sum((H(x_gaussian) * weights)) / None\n",
        "    ##end\n",
        "\n",
        "    return estimator\n",
        "\n",
        "# Set sample size\n",
        "N = 200\n",
        "\n",
        "# Run estimators\n",
        "mean_mc= monte_carlo_uniform(N)\n",
        "mean_is = importance_sampling_gaussian(N)\n",
        "\n",
        "print(f\"Monte Carlo (Uniform) - Estimation: {mean_mc},\")\n",
        "print(f\"Importance Sampling (Gaussian) - Estimation: {mean_is}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ighUZsI-XePB"
      },
      "outputs": [],
      "source": [
        "# Part 4: Comparing the varience of the estimators\n",
        "mc = np.zeros(10)\n",
        "is_ = np.zeros(10)\n",
        "for i in range(10):\n",
        "    mc[i] = monte_carlo_uniform(N)\n",
        "    is_[i] = importance_sampling_gaussian(N)\n",
        "print(f\"Monte Carlo estimators (Uniform): \", mc )\n",
        "print(f\"Monte Carlo (Uniform) - Variance: {np.var(mc)} \\n\")\n",
        "print(f\"Importance Sampling estimators (Gaussian): \", is_ )\n",
        "print(f\"Importance Sampling (Gaussian) - Variance: {np.var(is_)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1UrLbksYUOP"
      },
      "outputs": [],
      "source": [
        "# Part 4: why?\n",
        "\n",
        "# Generate x values between 0 and 10\n",
        "x = np.linspace(0, 10, 1000)\n",
        "\n",
        "# Compute H(x)\n",
        "H_values = H(x)\n",
        "\n",
        "# Compute the normal distribution N(5, 1)\n",
        "normal_values = norm.pdf(x, loc=5, scale=1)\n",
        "\n",
        "# Plot both functions\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, H_values, label=r'$H(x) = 10e^{-2|x-5|}$', color='blue', linewidth=2)\n",
        "plt.plot(x, normal_values, label=r'$N(5, 1)$', color='red', linestyle='--', linewidth=2)\n",
        "\n",
        "# Labels and title\n",
        "plt.title('Plot of $H(x)$ Vs. Normal Distribution $N(5,1)$', fontsize=14)\n",
        "plt.xlabel('x', fontsize=12)\n",
        "plt.ylabel('Density / Function Value', fontsize=12)\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tEfxE65SDu6g",
        "ZIOQ0AQ6Rv24",
        "vdviUP3iRw2Z"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}